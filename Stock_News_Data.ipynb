{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fetches the latest (past two weeks) news articles and their sentiment data for top 50 S&P 500 stocks**"
      ],
      "metadata": {
        "id": "xAl1_IQ3GEYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 50 S&P 500 stocks\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
        "tickers = sp500['Symbol'].tolist()\n",
        "\n",
        "market_caps = []\n",
        "\n",
        "for ticker in tickers:\n",
        "  info = yf.Ticker(ticker).info\n",
        "  market_cap = info.get('marketCap', None)\n",
        "  if market_cap:\n",
        "    market_caps.append([ticker, market_cap])\n",
        "\n",
        "market_caps.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "top_50_tickers = [stock[0] for stock in market_caps[:50]]\n",
        "\n",
        "print(top_50_tickers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETdN7_hLBgjc",
        "outputId": "3cdf14b2-ff63-48a5-e0b2-4864cfc06679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AAPL', 'MSFT', 'NVDA', 'GOOG', 'GOOGL', 'AMZN', 'META', 'AVGO', 'TSLA', 'WMT', 'LLY', 'JPM', 'V', 'UNH', 'MA', 'XOM', 'COST', 'NFLX', 'PG', 'ORCL', 'JNJ', 'HD', 'ABBV', 'KO', 'TMUS', 'BAC', 'PM', 'CRM', 'CVX', 'PLTR', 'CSCO', 'MCD', 'IBM', 'ABT', 'LIN', 'WFC', 'GE', 'T', 'MRK', 'PEP', 'VZ', 'AXP', 'ACN', 'MS', 'ISRG', 'RTX', 'NOW', 'TMO', 'INTU', 'BX']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import userdata\n",
        "\n",
        "ALPHA_VANTAGE_API_KEY = userdata.get('VANTAGE_API_KEY')\n",
        "\n",
        "# Fetches relevant articles with sentiment information from the past 2 weeks\n",
        "def fetch_news_sentiment_articles(ticker, limit=1000, time_from=None):\n",
        "\n",
        "    if time_from is None:\n",
        "        days_back = 14\n",
        "        time_from = (datetime.now() - timedelta(days=days_back)).strftime(\"%Y%m%dT0000\")\n",
        "\n",
        "    url = (\n",
        "        f\"https://www.alphavantage.co/query?function=NEWS_SENTIMENT\"\n",
        "        f\"&tickers={ticker}&limit={limit}&time_from={time_from}\"\n",
        "        f\"&apikey={ALPHA_VANTAGE_API_KEY}\"\n",
        "    )\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "      data = response.json()\n",
        "\n",
        "      if \"feed\" in data:\n",
        "          df = pd.DataFrame(data[\"feed\"])\n",
        "          useful_columns = [\"title\", \"summary\", \"source\", \"time_published\", \"topics\", \"overall_sentiment_label\", \"overall_sentiment_score\"]\n",
        "          available_cols = [col for col in useful_columns if col in df.columns]\n",
        "          if not available_cols:\n",
        "            print(f\"No expected columns found for {ticker}\")\n",
        "            return pd.DataFrame\n",
        "\n",
        "          df = df[available_cols]\n",
        "          df[\"ticker\"] = ticker\n",
        "          return df\n",
        "\n",
        "      else:\n",
        "          print(\"Error fetching data or no data available:\", data)\n",
        "          return pd.DataFrame()\n",
        "    else:\n",
        "        print(\"Error fetching data:\", response.status_code)\n",
        "\n",
        "output_folder = \"news_data\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Collecting articles from past 2 weeks for top 50 S&P 500 stocks\n",
        "for i in range(11,37):\n",
        "    ticker = top_50_tickers[i]\n",
        "    df_news = fetch_news_sentiment_articles(ticker)\n",
        "    if not df_news.empty:\n",
        "      path = f\"{output_folder}/{ticker}_news.csv\"\n",
        "      df_news.to_csv(path, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "sviVOQIhaoza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "laTNwes63q9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vl0h06aWIUGH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}